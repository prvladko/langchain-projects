{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd7e386-1321-48b0-8862-d00443f47d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d775e93-a233-4b88-9cbe-b79f96206f80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nLarge language models are deep neural networks that are trained on large corpora of text to generate natural language.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "llm(\"explain large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c399bdbe-468d-45fd-854a-7c3d75d5c199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e312c9-2590-4193-bd9e-e6ef6bbde609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0.3)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data \")\n",
    "]\n",
    "response=chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9b657f-ab56-4311-99d6-b5bba9abff1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is an example Python script that trains a neural network on simulated data:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "X = np.random.rand(1000, 10)\n",
      "y = np.sum(X, axis=1)\n",
      "\n",
      "# Define the neural network architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(64, input_dim=10, activation='relu'))\n",
      "model.add(Dense(32, activation='relu'))\n",
      "model.add(Dense(1, activation='linear'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='mean_squared_error', optimizer='adam')\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using NumPy's `random.rand()` function. We generate 1000 samples with 10 features each, and the target variable is the sum of the features.\n",
      "\n",
      "Next, we define the neural network architecture using Keras' `Sequential` model. We add three fully connected layers with 64, 32, and 1 neurons respectively. The first two layers use the ReLU activation function, while the output layer uses a linear activation function.\n",
      "\n",
      "We then compile the model using the mean squared error loss function and the Adam optimizer.\n",
      "\n",
      "Finally, we train the model on the simulated data using the `fit()` method. We train for 50 epochs with a batch size of 32, and use 20% of the data for validation.\n"
     ]
    }
   ],
   "source": [
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cf1b1-916c-4788-b021-c3e14a5de945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
